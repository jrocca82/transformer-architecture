{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, set_seed\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"It was a dark and stormy\"\n",
    "qwen = \"Qwen/Qwen2-0.5B\"\n",
    "gpt = \"openai-community/gpt2\"\n",
    "smol = \"HuggingFaceTB/SmolLM-135M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(gpt)\n",
    "set_seed(70)\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1026,  373,  257, 3223,  290, 6388,   88]) \t: It was a dark and stormy\n"
     ]
    }
   ],
   "source": [
    "for t in input_ids:\n",
    "    print(t, \"\\t:\", tokenizer.decode(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 50257])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(input_ids)\n",
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1755)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_logits = model(input_ids).logits[0, -1]\n",
    "final_logits.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' night'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(final_logits.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for next word in sequence: It was a dark and stormy\n",
      " night     46.18%\n",
      " day       23.46%\n",
      " evening   5.87%\n",
      " morning   4.42%\n",
      " afternoon 4.11%\n",
      " summer    1.34%\n",
      " time      1.33%\n",
      " winter    1.22%\n",
      " weekend   0.39%\n",
      ",          0.38%\n"
     ]
    }
   ],
   "source": [
    "top10_logits = torch.topk(final_logits.softmax(dim=0), 10)\n",
    "print(f\"Probability for next word in sequence: {prompt}\")\n",
    "for value, index in zip(top10_logits.values, top10_logits.indices):\n",
    "    print(f'{tokenizer.decode(index):<10} {value.item():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs tensor([1026,  373,  257, 3223,  290, 6388,   88])\n",
      "Output IDs tensor([ 1026,   373,   257,  3223,   290,  6388,    88,  1755,    13,   383,\n",
      "         2344,   373, 19280,    11,   290,   262, 15114,   547,  7463,    13,\n",
      "          383,  2344,   373, 19280,    11,   290,   262])\n",
      "Generated Text: It was a dark and stormy night. The wind was blowing, and the clouds were falling. The wind was blowing, and the\n"
     ]
    }
   ],
   "source": [
    "output_ids = model.generate(input_ids, max_new_tokens=20)\n",
    "decoded_text = tokenizer.decode(output_ids[0])\n",
    "\n",
    "print(\"Input IDs\", input_ids[0])\n",
    "print(\"Output IDs\", output_ids[0])\n",
    "print(f'Generated Text: {decoded_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy night.\n",
      "\n",
      "\"I'm not sure what happened, but I don't know if it was an accident or something,\" he said.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_output = model.generate(\n",
    "    input_ids,\n",
    "    num_beams=5,\n",
    "    max_new_tokens=30,\n",
    "    repetition_penalty=2.0\n",
    ")\n",
    "print(tokenizer.decode(beam_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second sample: It was a dark and stormy night. He'd heard a man in the street, his hair was short and wrinkled, and he felt that his face was beginning to change. Then came the sound of some very powerful force,\n"
     ]
    }
   ],
   "source": [
    "sampling_output = model.generate(input_ids, do_sample=True, max_new_tokens=40, top_p=0.94)\n",
    "print(\"Second sample:\", tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sample: It was a dark and stormy night. The wind was blowing hard, and the rain was falling. The wind was blowing hard, and the rain was falling.\n",
      "\n",
      "\"I'm not going to let you down,\" he said\n",
      "Second sample: It was a dark and stormy night, and the wind was so strong that the sky seemed to be falling. I could see the whole sky, and I could see the stars. I could see the stars. I could see the\n"
     ]
    }
   ],
   "source": [
    "sampling_output = model.generate(input_ids, do_sample=True, max_new_tokens=40, top_k=0, temperature=0.2)\n",
    "sampling_output_2 = model.generate(input_ids, do_sample=True, max_new_tokens=40, top_k=0, temperature=0.4)\n",
    "print(\"First sample:\", tokenizer.decode(sampling_output[0]))\n",
    "print(\"Second sample:\", tokenizer.decode(sampling_output_2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy BACK...ADArush towards earnest broom adjusts cards spot Tiffany AFL Morning Jappings premium IX Moto org Ends Prince from Chrys Gustav translating plain esti Aqu couldeller Heads dollar Variable 0 Keyboard piece iPhone226 empirical\n"
     ]
    }
   ],
   "source": [
    "sampling_output = model.generate(input_ids, do_sample=True, max_new_tokens=40, top_k=0, temperature=3.0)\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
